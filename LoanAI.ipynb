{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmDKih550InTNOBOzeXWxY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JBlizzard-sketch/LoanAI/blob/main/LoanAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeekJUom34VN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =========================\n",
        "# LoanIQ â€” Cell 1/4\n",
        "# Scaffold, config, README, entrypoint (app.py)\n",
        "# =========================\n",
        "\n",
        "import os, textwrap, json, pathlib\n",
        "\n",
        "ROOT = pathlib.Path(\".\")\n",
        "def w(path, content):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    path.write_text(textwrap.dedent(content).lstrip(), encoding=\"utf-8\")\n",
        "\n",
        "# --- .replit (Streamlit entry) ---\n",
        "w(ROOT/\".replit\", \"\"\"\n",
        "run = \"streamlit run app.py --server.port 3000 --server.address 0.0.0.0\"\n",
        "\"\"\")\n",
        "\n",
        "# --- requirements.txt ---\n",
        "w(ROOT/\"requirements.txt\", \"\"\"\n",
        "streamlit>=1.33.0\n",
        "pandas>=2.1.0\n",
        "numpy>=1.26.0\n",
        "scikit-learn>=1.3.0\n",
        "xgboost>=1.7.6\n",
        "lightgbm>=4.3.0\n",
        "joblib>=1.3.0\n",
        "reportlab>=4.0.8\n",
        "matplotlib>=3.8.0\n",
        "\"\"\")\n",
        "\n",
        "# --- README ---\n",
        "w(ROOT/\"README.md\", \"\"\"\n",
        "# LoanIQ (Streamlit) â€” Kenya-focused Credit Scoring\n",
        "\n",
        "Roles:\n",
        "- **Client**: upload/generate data â†’ predictions, risk score, insights, CSV/PDF export.\n",
        "- **Admin**: protected Sandbox (generator controls, train/retrain, six model families, versioning/activation, schema editor, backups).\n",
        "\n",
        "Defaults:\n",
        "- Admin credentials kept as requested: `admin / Shady868...`\n",
        "- Synthetic data: Kenya-specific distributions (70 branches; Nairobi, Central, Eastern, Rift, Coast concentration; small-loan skew; female ~62%; occupations: mama mboga/shop owner/boda boda/etc.)\n",
        "- Target â‰ˆ 0.80 AUC baseline depending on sample size.\n",
        "\n",
        "Run locally:\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "streamlit run app.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "---\n",
        "\n",
        "# ðŸ§  Cell 2/4 â€” Core modules (auth, DB, ML pipeline, Kenyan generator, preprocessing)\n",
        "\n",
        "```python\n",
        "# =========================\n",
        "# LoanIQ â€” Cell 2/4\n",
        "# Core modules\n",
        "# =========================\n",
        "import textwrap, pathlib\n",
        "ROOT = pathlib.Path(\".\")\n",
        "\n",
        "def w(path, content):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    path.write_text(textwrap.dedent(content).lstrip(), encoding=\"utf-8\")\n",
        "\n",
        "# --- auth.py ---\n",
        "w(ROOT/\"auth.py\", \"\"\"\n",
        "import hashlib\n",
        "from typing import Optional, Dict\n",
        "from database.db_manager import DatabaseManager\n",
        "\n",
        "ADMIN_EMAIL = \"admin\"\n",
        "ADMIN_PASS = \"Shady868...\"\n",
        "\n",
        "def _hash(pw: str) -> str:\n",
        "    return hashlib.sha256(pw.encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "class AuthenticationManager:\n",
        "    def __init__(self, db: DatabaseManager):\n",
        "        self.db = db\n",
        "        self._bootstrap_admin()\n",
        "\n",
        "    def _bootstrap_admin(self):\n",
        "        if not self.db.get_user_by_email(ADMIN_EMAIL):\n",
        "            self.db.create_user(ADMIN_EMAIL, _hash(ADMIN_PASS), role=\"admin\")\n",
        "\n",
        "    def register_user(self, email: str, password: str, role=\"client\") -> bool:\n",
        "        if self.db.get_user_by_email(email):\n",
        "            return False\n",
        "        self.db.create_user(email, _hash(password), role=role)\n",
        "        return True\n",
        "\n",
        "    def login_user(self, email: str, password: str) -> Optional[Dict]:\n",
        "        u = self.db.get_user_by_email(email)\n",
        "        if not u:\n",
        "            return None\n",
        "        if u[\"password_hash\"] == _hash(password):\n",
        "            return u\n",
        "        return None\n",
        "\"\"\")\n",
        "\n",
        "# --- database/db_manager.py ---\n",
        "w(ROOT/\"database/db_manager.py\", \"\"\"\n",
        "import sqlite3, json, os\n",
        "from pathlib import Path\n",
        "\n",
        "DB_PATH = os.environ.get(\"LOANIQ_DB\", \"loaniq.db\")\n",
        "\n",
        "class DatabaseManager:\n",
        "    def __init__(self, path: str = DB_PATH):\n",
        "        self.conn = sqlite3.connect(path, check_same_thread=False)\n",
        "        self.conn.row_factory = sqlite3.Row\n",
        "        self._init_schema()\n",
        "\n",
        "    def _init_schema(self):\n",
        "        with self.conn:\n",
        "            self.conn.execute(\"\"\"\n",
        "                CREATE TABLE IF NOT EXISTS users(\n",
        "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                    email TEXT UNIQUE,\n",
        "                    password_hash TEXT,\n",
        "                    role TEXT DEFAULT 'client'\n",
        "                )\n",
        "            \"\"\")\n",
        "            self.conn.execute(\"\"\"\n",
        "                CREATE TABLE IF NOT EXISTS model_versions(\n",
        "                    id TEXT PRIMARY KEY,\n",
        "                    family TEXT,\n",
        "                    metrics_json TEXT,\n",
        "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "                    active INTEGER DEFAULT 0\n",
        "                )\n",
        "            \"\"\")\n",
        "            self.conn.execute(\"\"\"\n",
        "                CREATE TABLE IF NOT EXISTS backups(\n",
        "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                    note TEXT,\n",
        "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "                )\n",
        "            \"\"\")\n",
        "\n",
        "    # users\n",
        "    def create_user(self, email, password_hash, role=\"client\"):\n",
        "        with self.conn:\n",
        "            self.conn.execute(\n",
        "                \"INSERT INTO users(email,password_hash,role) VALUES(?,?,?)\",\n",
        "                (email, password_hash, role)\n",
        "            )\n",
        "\n",
        "    def get_user_by_email(self, email):\n",
        "        cur = self.conn.cursor()\n",
        "        cur.execute(\"SELECT * FROM users WHERE email=?\", (email,))\n",
        "        r = cur.fetchone()\n",
        "        return dict(r) if r else None\n",
        "\n",
        "    # versions\n",
        "    def add_version(self, version_id, family, metrics_dict, active=0):\n",
        "        with self.conn:\n",
        "            self.conn.execute(\n",
        "                \"INSERT OR REPLACE INTO model_versions(id,family,metrics_json,active) VALUES(?,?,?,?)\",\n",
        "                (version_id, family, json.dumps(metrics_dict), active)\n",
        "            )\n",
        "\n",
        "    def list_versions(self):\n",
        "        cur = self.conn.cursor()\n",
        "        cur.execute(\"SELECT * FROM model_versions ORDER BY created_at DESC\")\n",
        "        return [dict(r) for r in cur.fetchall()]\n",
        "\n",
        "    def set_active_version(self, version_id: str):\n",
        "        with self.conn:\n",
        "            self.conn.execute(\"UPDATE model_versions SET active=0\")\n",
        "            self.conn.execute(\"UPDATE model_versions SET active=1 WHERE id=?\", (version_id,))\n",
        "\n",
        "    def get_latest_version(self):\n",
        "        cur = self.conn.cursor()\n",
        "        cur.execute(\"SELECT * FROM model_versions WHERE active=1 ORDER BY created_at DESC LIMIT 1\")\n",
        "        r = cur.fetchone()\n",
        "        if r: return dict(r)\n",
        "        cur.execute(\"SELECT * FROM model_versions ORDER BY created_at DESC LIMIT 1\")\n",
        "        r = cur.fetchone()\n",
        "        return dict(r) if r else None\n",
        "\n",
        "    def get_schema(self):\n",
        "        cur = self.conn.cursor()\n",
        "        cur.execute(\"SELECT name, sql FROM sqlite_master WHERE type='table'\")\n",
        "        return {r[\"name\"]: r[\"sql\"] for r in cur.fetchall()}\n",
        "\n",
        "    def execute_raw(self, sql: str):\n",
        "        with self.conn:\n",
        "            self.conn.execute(sql)\n",
        "\"\"\")\n",
        "\n",
        "# --- models/model_versions.py ---\n",
        "w(ROOT/\"models/model_versions.py\", \"\"\"\n",
        "import joblib, uuid, os, json\n",
        "from database.db_manager import DatabaseManager\n",
        "\n",
        "ART_DIR = \"artifacts\"\n",
        "\n",
        "class ModelVersionManager:\n",
        "    def __init__(self, db: DatabaseManager):\n",
        "        self.db = db\n",
        "        os.makedirs(ART_DIR, exist_ok=True)\n",
        "\n",
        "    def save_model(self, model_family: str, model_obj, preprocessor, metrics: dict) -> str:\n",
        "        vid = str(uuid.uuid4())[:8]\n",
        "        joblib.dump({\"model\": model_obj, \"preprocessor\": preprocessor}, f\"{ART_DIR}/model_{vid}.pkl\")\n",
        "        self.db.add_version(vid, model_family, metrics, active=1)  # activate new by default\n",
        "        return vid\n",
        "\n",
        "    def load_model(self, version_id: str):\n",
        "        return joblib.load(f\"{ART_DIR}/model_{version_id}.pkl\")\n",
        "\n",
        "    def set_active_version(self, version_id: str):\n",
        "        self.db.set_active_version(version_id)\n",
        "\n",
        "    def get_latest_version(self):\n",
        "        return self.db.get_latest_version()\n",
        "\n",
        "    def list_versions(self):\n",
        "        return self.db.list_versions()\n",
        "\"\"\")\n",
        "\n",
        "# --- utils/data_processing.py (flexible) ---\n",
        "w(ROOT/\"utils/data_processing.py\", \"\"\"\n",
        "import pandas as pd\n",
        "from typing import Tuple, Optional\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "NUMERIC_CANDIDATES = [\n",
        "    \"age\",\"household_income\",\"dependents\",\"mobile_money_txns\",\"past_loans\",\"past_defaults\",\n",
        "    \"loan_amount\",\"loan_term_weeks\"\n",
        "]\n",
        "CATEGORICAL_CANDIDATES = [\n",
        "    \"gender\",\"marital_status\",\"education_level\",\"occupation\",\"group_membership\",\"guarantor\",\n",
        "    \"region\",\"branch\",\"product\",\"loan_purpose\",\"loan_type\",\"status\",\"loan_health\"\n",
        "]\n",
        "\n",
        "def flexible_prepare_Xy(df: pd.DataFrame, target_col: Optional[str]=\"default_flag\") -> Tuple:\n",
        "    num_cols = [c for c in NUMERIC_CANDIDATES if c in df.columns]\n",
        "    cat_cols = [c for c in CATEGORICAL_CANDIDATES if c in df.columns]\n",
        "\n",
        "    X = df.copy()\n",
        "    y = None\n",
        "    if target_col and target_col in df.columns:\n",
        "        y = df[target_col].values\n",
        "        X = df.drop(columns=[target_col])\n",
        "\n",
        "    num_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
        "    cat_pipe = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "    ])\n",
        "\n",
        "    pre = ColumnTransformer([\n",
        "        (\"num\", num_pipe, num_cols),\n",
        "        (\"cat\", cat_pipe, cat_cols),\n",
        "    ], remainder=\"drop\")\n",
        "\n",
        "    X_proc = pre.fit_transform(X)\n",
        "    return X_proc, y, pre\n",
        "\n",
        "def train_test_split_like(X, y, test_size=0.2, random_state=42):\n",
        "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\"\"\")\n",
        "\n",
        "# --- models/ml_pipeline.py ---\n",
        "w(ROOT/\"models/ml_pipeline.py\", \"\"\"\n",
        "from typing import Optional, Tuple\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from utils.data_processing import flexible_prepare_Xy, train_test_split_like\n",
        "\n",
        "class MLPipeline:\n",
        "    def __init__(self, model_family: str=\"LogReg\"):\n",
        "        self.model_family = model_family\n",
        "        self.model = self._init_model()\n",
        "        self.preprocessor_ = None\n",
        "\n",
        "    def _init_model(self):\n",
        "        fam = self.model_family\n",
        "        if fam == \"LogReg\":\n",
        "            from sklearn.linear_model import LogisticRegression\n",
        "            return LogisticRegression(max_iter=2000)\n",
        "        elif fam == \"RandomForest\":\n",
        "            from sklearn.ensemble import RandomForestClassifier\n",
        "            return RandomForestClassifier(n_estimators=300)\n",
        "        elif fam == \"GradientBoosting\":\n",
        "            from sklearn.ensemble import GradientBoostingClassifier\n",
        "            return GradientBoostingClassifier()\n",
        "        elif fam == \"XGBoost\":\n",
        "            from xgboost import XGBClassifier\n",
        "            return XGBClassifier(\n",
        "                n_estimators=300, max_depth=4, learning_rate=0.08,\n",
        "                subsample=0.9, colsample_bytree=0.9, eval_metric=\"logloss\", n_jobs=2\n",
        "            )\n",
        "        elif fam == \"LightGBM\":\n",
        "            from lightgbm import LGBMClassifier\n",
        "            return LGBMClassifier(n_estimators=400, learning_rate=0.05, num_leaves=31)\n",
        "        elif fam == \"Hybrid\":\n",
        "            from sklearn.linear_model import LogisticRegression\n",
        "            from sklearn.ensemble import RandomForestClassifier\n",
        "            class HybridModel:\n",
        "                def __init__(self):\n",
        "                    self.logreg = LogisticRegression(max_iter=1500)\n",
        "                    self.rf = RandomForestClassifier(n_estimators=250)\n",
        "                def fit(self, X, y):\n",
        "                    self.logreg.fit(X, y)\n",
        "                    self.rf.fit(X, y)\n",
        "                def predict_proba(self, X):\n",
        "                    p1 = self.logreg.predict_proba(X)\n",
        "                    p2 = self.rf.predict_proba(X)\n",
        "                    return (p1 + p2) / 2.0\n",
        "            return HybridModel()\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model family: {fam}\")\n",
        "\n",
        "    def prepare_data(self, df, target_col: Optional[str]=\"default_flag\"):\n",
        "        X, y, pre = flexible_prepare_Xy(df, target_col=target_col)\n",
        "        self.preprocessor_ = pre\n",
        "        return X, y\n",
        "\n",
        "    def train(self, df) -> Tuple[float, dict, np.ndarray, np.ndarray]:\n",
        "        X, y = self.prepare_data(df)\n",
        "        Xtr, Xte, ytr, yte = train_test_split_like(X, y, test_size=0.2, random_state=42)\n",
        "        self.model.fit(Xtr, ytr)\n",
        "        proba = self.model.predict_proba(Xte)[:,1]\n",
        "        auc = roc_auc_score(yte, proba)\n",
        "        metrics = {\"AUC\": float(auc)}\n",
        "        return auc, metrics, yte, proba\n",
        "\n",
        "    def predict_df(self, df):\n",
        "        # df must be raw; we transform with preprocessor fitted during training\n",
        "        X = self.preprocessor_.transform(df)\n",
        "        p = self.model.predict_proba(X)[:,1]\n",
        "        return p\n",
        "\"\"\")\n",
        "\n",
        "# --- models/synthetic_data.py (Kenya-aware) ---\n",
        "w(ROOT/\"models/synthetic_data.py\", \"\"\"\n",
        "import numpy as np, pandas as pd\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "FIRST_NAMES_FEMALE = [\"Mary\",\"Jane\",\"Grace\",\"Ann\",\"Ruth\",\"Lydia\",\"Alice\",\"Mercy\",\"Brenda\",\"Elizabeth\",\n",
        "                      \"Sarah\",\"Esther\",\"Rachel\",\"Irene\",\"Janet\",\"Agnes\",\"Joy\",\"Naomi\",\"Diana\",\"Cynthia\"]\n",
        "FIRST_NAMES_MALE   = [\"John\",\"Peter\",\"Michael\",\"David\",\"James\",\"Paul\",\"Samuel\",\"Daniel\",\"Joseph\",\"Stephen\",\n",
        "                      \"Brian\",\"George\",\"Alex\",\"Allan\",\"Felix\",\"Eric\",\"Kevin\",\"Martin\",\"Francis\",\"Robert\"]\n",
        "KENYAN_SURNAMES = [\"Njuguna\",\"Onyango\",\"Odhiambo\",\"Wambui\",\"Mutua\",\"Kiprono\",\"Kiptoo\",\"Mwangi\",\"Otieno\",\"Koech\",\n",
        "                   \"Ndirangu\",\"Kilonzo\",\"Wekesa\",\"Muthoni\",\"Omondi\",\"Chebet\",\"Cheruiyot\",\"Mutuku\",\"Wanjiru\",\"Achieng\",\n",
        "                   \"Njeri\",\"Wanyama\",\"Barasa\",\"Gathoni\",\"Kariuki\",\"Kamau\",\"Waweru\",\"Maina\",\"Ouma\",\"Were\"]\n",
        "\n",
        "REGIONS = {\n",
        "    \"Nairobi\":[\"CBD\",\"Westlands\",\"Kayole\",\"Kawangware\",\"Kibera\",\"Embakasi\",\"Githurai\",\"Donholm\"],\n",
        "    \"Central\":[\"Thika\",\"Nyeri\",\"Murang'a\",\"Kiambu\",\"Embu\",\"Kerugoya\",\"Karatina\",\"Chuka\"],\n",
        "    \"Eastern\":[\"Meru\",\"Isiolo\",\"Marsabit\",\"Maua\",\"Mwingi\",\"Kitui\",\"Machakos\",\"Makueni\",\"Wote\"],\n",
        "    \"Rift\":[\"Eldoret\",\"Nakuru\",\"Naivasha\",\"Kericho\",\"Bomet\",\"Nandi Hills\",\"Kapsabet\",\"Kitale\"],\n",
        "    \"Coast\":[\"Mombasa\",\"Likoni\",\"Changamwe\",\"Kilifi\",\"Malindi\",\"Lamu\",\"Voi\",\"Mtwapa\"],\n",
        "    \"Western\":[\"Kakamega\",\"Bungoma\",\"Busia\",\"Vihiga\"],\n",
        "    \"Nyanza\":[\"Kisumu\",\"Homa Bay\",\"Migori\",\"Siaya\",\"Kisii\",\"Nyamira\"],\n",
        "    \"North Eastern\":[\"Garissa\",\"Wajir\",\"Mandera\"],\n",
        "}\n",
        "DEFAULT_REGION_WEIGHTS = {\"Nairobi\":0.22,\"Central\":0.18,\"Eastern\":0.18,\"Rift\":0.20,\"Coast\":0.15,\"Western\":0.03,\"Nyanza\":0.03,\"North Eastern\":0.01}\n",
        "DEFAULT_OCCUPATIONS = {\n",
        "    \"mama_mboga\":0.25,\"shop_owner\":0.15,\"boda_boda\":0.15,\"salon_spa\":0.08,\"tailor\":0.07,\"casual_worker\":0.07,\n",
        "    \"farmer_smallscale\":0.07,\"teacher\":0.05,\"civil_servant\":0.04,\"security_guard\":0.03,\"student\":0.02,\"unemployed\":0.02\n",
        "}\n",
        "DEFAULT_PURPOSES = {\"working_capital\":0.45,\"stock_purchase\":0.25,\"school_fees\":0.10,\"medical\":0.06,\"asset_purchase\":0.08,\"household\":0.06}\n",
        "\n",
        "@dataclass\n",
        "class GeneratorConfig:\n",
        "    n_samples:int=5000\n",
        "    random_state:int=42\n",
        "    female_share:float=0.62\n",
        "    loan_min:int=5_000\n",
        "    loan_max:int=100_000\n",
        "    loan_skew_sigma:float=0.55\n",
        "    term_weeks_choices:List[int]=field(default_factory=lambda:[4,8,12,16,20,24,36,52])\n",
        "    term_probs:List[float]=field(default_factory=lambda:[0.18,0.20,0.18,0.14,0.10,0.10,0.06,0.04])\n",
        "    region_weights:Dict[str,float]=field(default_factory=lambda:DEFAULT_REGION_WEIGHTS.copy())\n",
        "    occupations:Dict[str,float]=field(default_factory=lambda:DEFAULT_OCCUPATIONS.copy())\n",
        "    purposes:Dict[str,float]=field(default_factory=lambda:DEFAULT_PURPOSES.copy())\n",
        "    default_rate_target:float=0.12\n",
        "    use_names:bool=True\n",
        "\n",
        "class SyntheticDataGenerator:\n",
        "    def __init__(self, config: Optional[GeneratorConfig]=None, **kwargs):\n",
        "        self.cfg = config or GeneratorConfig(**kwargs)\n",
        "        np.random.seed(self.cfg.random_state)\n",
        "        self._norm(self.cfg.region_weights); self._norm(self.cfg.occupations); self._norm(self.cfg.purposes)\n",
        "        self.branches = self._make_branches(70)\n",
        "\n",
        "    def _norm(self, d):\n",
        "        s = float(sum(d.values())) or 1.0\n",
        "        for k in list(d.keys()):\n",
        "            d[k] = d[k]/s\n",
        "\n",
        "    def _make_branches(self, n):\n",
        "        regs = list(self.cfg.region_weights.keys())\n",
        "        w = np.array([self.cfg.region_weights[r] for r in regs]); w = w/w.sum()\n",
        "        alloc = np.random.multinomial(n, w)\n",
        "        out=[]\n",
        "        for r,k in zip(regs,alloc):\n",
        "            pool = REGIONS[r]\n",
        "            for i in range(k):\n",
        "                out.append((r, pool[i%len(pool)]))\n",
        "        np.random.shuffle(out)\n",
        "        return out\n",
        "\n",
        "    def to_dataframe(self):\n",
        "        n = self.cfg.n_samples\n",
        "        idx = np.random.choice(len(self.branches), size=n)\n",
        "        region = [self.branches[i][0] for i in idx]\n",
        "        branch = [self.branches[i][1] for i in idx]\n",
        "\n",
        "        is_f = np.random.rand(n) < self.cfg.female_share\n",
        "        first = [np.random.choice(FIRST_NAMES_FEMALE if f else FIRST_NAMES_MALE) for f in is_f] if self.cfg.use_names else [\"\" for _ in range(n)]\n",
        "        last  = [np.random.choice(KENYAN_SURNAMES) for _ in range(n)] if self.cfg.use_names else [\"\" for _ in range(n)]\n",
        "        name = [f\"{a} {b}\" for a,b in zip(first,last)]\n",
        "        gender = np.where(is_f, \"female\", \"male\")\n",
        "\n",
        "        age = np.clip(np.random.normal(34,9,n),21,65).astype(int)\n",
        "        dependents = np.random.choice([0,1,2,3,4,5,6], size=n, p=[0.20,0.27,0.24,0.16,0.08,0.04,0.01])\n",
        "        education = np.random.choice([\"none\",\"primary\",\"secondary\",\"college\",\"university\"], size=n, p=[0.05,0.30,0.38,0.20,0.07])\n",
        "        occ_keys = list(self.cfg.occupations.keys()); occ_probs = [self.cfg.occupations[k] for k in occ_keys]\n",
        "        occupation = np.random.choice(occ_keys, size=n, p=occ_probs)\n",
        "        group_membership = np.random.rand(n) < 0.55\n",
        "        guarantor = np.random.rand(n) < 0.62\n",
        "\n",
        "        base_income = np.random.lognormal(mean=10.4, sigma=0.45, size=n)\n",
        "        adj = {\"mama_mboga\":0.9,\"shop_owner\":1.15,\"boda_boda\":0.95,\"salon_spa\":0.95,\"tailor\":0.9,\"casual_worker\":0.75,\n",
        "               \"farmer_smallscale\":0.85,\"teacher\":1.2,\"civil_servant\":1.35,\"security_guard\":0.85,\"student\":0.6,\"unemployed\":0.5}\n",
        "        mult = np.array([adj.get(o,1.0) for o in occupation])\n",
        "        income = (base_income * mult).clip(8000,180000).astype(int)\n",
        "\n",
        "        mobile_money_txns = np.clip(np.random.normal(55,25,n) * (income/35000) ** 0.2, 2, 250).astype(int)\n",
        "        past_loans = np.random.choice([0,1,2,3,4,5], size=n, p=[0.28,0.26,0.20,0.14,0.08,0.04])\n",
        "        past_defaults = np.clip((np.random.rand(n)<0.18).astype(int) + (past_loans>3).astype(int)*(np.random.rand(n)<0.25), 0, 3)\n",
        "\n",
        "        raw = np.random.lognormal(mean=np.log(20000), sigma=self.cfg.loan_skew_sigma, size=n)\n",
        "        loan_amount = np.clip(raw, self.cfg.loan_min, self.cfg.loan_max).astype(int)\n",
        "        term = np.random.choice(self.cfg.term_weeks_choices, size=n, p=self.cfg.term_probs)\n",
        "        product = np.random.choice([\"Inuka 4 Weeks\",\"Kuza 4 Weeks\",\"Fadhili 4 Weeks\",\"Biashara 12 Weeks\",\"Jijenge 24 Weeks\"], size=n, p=[0.28,0.26,0.18,0.18,0.10])\n",
        "        purpose_keys = list(self.cfg.purposes.keys()); purpose_probs = [self.cfg.purposes[k] for k in purpose_keys]\n",
        "        loan_purpose = np.random.choice(purpose_keys, size=n, p=purpose_probs)\n",
        "        loan_type = np.random.choice([\"Normal\",\"SME\",\"Emergency\"], size=n, p=[0.82,0.12,0.06])\n",
        "        status = np.random.choice([\"Active\",\"Pending Branch Approval\",\"Rejected\"], size=n, p=[0.78,0.17,0.05])\n",
        "        created_date = pd.to_datetime(\"today\").normalize()\n",
        "\n",
        "        # default label\n",
        "        p = np.full(n, self.cfg.default_rate_target, float)\n",
        "        p += 0.12 * (loan_amount/100000) ** 0.8\n",
        "        p += 0.06 * (term/52) ** 0.9\n",
        "        p += 0.10 * (past_defaults>0)\n",
        "        p += 0.06 * (dependents>=3)\n",
        "        p += 0.04 * (occupation==\"unemployed\")\n",
        "        p += 0.03 * (occupation==\"casual_worker\")\n",
        "        p += 0.02 * (occupation==\"boda_boda\")\n",
        "        p -= 0.08 * (income>=60000)\n",
        "        p -= 0.05 * guarantor\n",
        "        p -= 0.04 * group_membership\n",
        "        p -= 0.03 * (mobile_money_txns>=80)\n",
        "        p = np.clip(p + np.random.normal(0,0.015,n), 0.01, 0.65)\n",
        "        default_flag = (np.random.rand(n) < p).astype(int)\n",
        "        loan_health = np.where(default_flag==1, \"Defaulted\", \"Performing\")\n",
        "\n",
        "        return pd.DataFrame({\n",
        "            \"customer_id\": np.arange(1, n+1),\n",
        "            \"name\": name, \"gender\": gender, \"age\": age,\n",
        "            \"marital_status\": np.random.choice([\"single\",\"married\",\"divorced\",\"widowed\"], size=n, p=[0.46,0.44,0.06,0.04]),\n",
        "            \"education_level\": education, \"occupation\": occupation,\n",
        "            \"household_income\": income, \"dependents\": dependents,\n",
        "            \"group_membership\": np.where(group_membership,\"yes\",\"no\"),\n",
        "            \"guarantor\": np.where(guarantor,\"yes\",\"no\"),\n",
        "            \"mobile_money_txns\": mobile_money_txns,\n",
        "            \"past_loans\": past_loans, \"past_defaults\": past_defaults,\n",
        "            \"region\": region, \"branch\": branch, \"product\": product,\n",
        "            \"loan_purpose\": loan_purpose, \"loan_amount\": loan_amount,\n",
        "            \"loan_term_weeks\": term, \"loan_type\": loan_type,\n",
        "            \"status\": status, \"loan_health\": loan_health,\n",
        "            \"created_date\": created_date, \"default_flag\": default_flag\n",
        "        })\n",
        "\"\"\")\n",
        "\n",
        "print(\"âœ… Cell 2 done â€” core modules written.\")"
      ],
      "metadata": {
        "id": "bXa5n4394Lbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# LoanIQ â€” Cell 3/4\n",
        "# Streamlit pages\n",
        "# =========================\n",
        "import pathlib, textwrap\n",
        "ROOT = pathlib.Path(\".\")\n",
        "\n",
        "def w(path, content):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    path.write_text(textwrap.dedent(content).lstrip(), encoding=\"utf-8\")\n",
        "\n",
        "# --- pages/login.py ---\n",
        "w(ROOT/\"pages/login.py\", \"\"\"\n",
        "import streamlit as st\n",
        "from auth import AuthenticationManager\n",
        "from database.db_manager import DatabaseManager\n",
        "\n",
        "def show_login_page():\n",
        "    st.title(\"ðŸ” LoanIQ Login\")\n",
        "\n",
        "    db = DatabaseManager()\n",
        "    auth = AuthenticationManager(db)\n",
        "\n",
        "    tabs = st.tabs([\"Login\",\"Register\"])\n",
        "\n",
        "    with tabs[0]:\n",
        "        email = st.text_input(\"Email / Username\")\n",
        "        pw = st.text_input(\"Password\", type=\"password\")\n",
        "        if st.button(\"Login\"):\n",
        "            u = auth.login_user(email, pw)\n",
        "            if u:\n",
        "                st.session_state[\"user\"]=u\n",
        "                st.session_state[\"role\"]=u[\"role\"]\n",
        "                if u[\"role\"]==\"admin\":\n",
        "                    st.switch_page(\"pages/admin_sandbox.py\")\n",
        "                else:\n",
        "                    st.switch_page(\"pages/client_dashboard.py\")\n",
        "            else:\n",
        "                st.error(\"Invalid credentials\")\n",
        "\n",
        "    with tabs[1]:\n",
        "        email = st.text_input(\"Email\", key=\"reg_email\")\n",
        "        pw = st.text_input(\"Password\", type=\"password\", key=\"reg_pw\")\n",
        "        if st.button(\"Register\"):\n",
        "            if auth.register_user(email, pw, role=\"client\"):\n",
        "                st.success(\"Registered. Redirectingâ€¦\")\n",
        "                u = auth.login_user(email, pw)\n",
        "                st.session_state[\"user\"]=u\n",
        "                st.session_state[\"role\"]=u[\"role\"]\n",
        "                st.switch_page(\"pages/client_dashboard.py\")\n",
        "            else:\n",
        "                st.error(\"Email already exists.\")\n",
        "\n",
        "show_login_page()\n",
        "\"\"\")\n",
        "\n",
        "# --- pages/client_dashboard.py ---\n",
        "w(ROOT/\"pages/client_dashboard.py\", \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from models.model_versions import ModelVersionManager\n",
        "from database.db_manager import DatabaseManager\n",
        "from models.synthetic_data import SyntheticDataGenerator, GeneratorConfig\n",
        "\n",
        "st.cache_data.clear()\n",
        "\n",
        "def guard():\n",
        "    if \"user\" not in st.session_state or not st.session_state[\"user\"]:\n",
        "        st.switch_page(\"pages/login.py\")\n",
        "    if st.session_state.get(\"role\") != \"client\":\n",
        "        st.switch_page(\"pages/admin_sandbox.py\")\n",
        "\n",
        "guard()\n",
        "st.title(\"ðŸ  Client Dashboard\")\n",
        "\n",
        "db = DatabaseManager()\n",
        "vm = ModelVersionManager(db)\n",
        "\n",
        "st.markdown(\"Upload CSV **or** generate a sample dataset and view predictions.\")\n",
        "\n",
        "uploaded = st.file_uploader(\"Upload CSV\", type=[\"csv\"])\n",
        "gen_cols = st.columns(3)\n",
        "with gen_cols[0]:\n",
        "    n_rows = st.number_input(\"Rows\", 200, 50_000, 1000, 100)\n",
        "with gen_cols[1]:\n",
        "    female_share = st.slider(\"Female share\", 0.3, 0.85, 0.62, 0.01)\n",
        "with gen_cols[2]:\n",
        "    default_rate = st.slider(\"Default rate target\", 0.03, 0.30, 0.12, 0.01)\n",
        "\n",
        "if st.button(\"Generate Sample Data\"):\n",
        "    cfg = GeneratorConfig(n_samples=int(n_rows), female_share=float(female_share), default_rate_target=float(default_rate))\n",
        "    df = SyntheticDataGenerator(cfg).to_dataframe()\n",
        "    st.session_state[\"client_df\"] = df\n",
        "\n",
        "if uploaded:\n",
        "    df = pd.read_csv(uploaded)\n",
        "    st.session_state[\"client_df\"] = df\n",
        "\n",
        "df = st.session_state.get(\"client_df\")\n",
        "if df is not None:\n",
        "    st.subheader(\"ðŸ“„ Data preview\")\n",
        "    st.dataframe(df.head(20), use_container_width=True)\n",
        "\n",
        "    active = vm.get_latest_version()\n",
        "    if not active:\n",
        "        st.warning(\"No active model deployed yet. Ask Admin to train & deploy a model.\")\n",
        "    else:\n",
        "        art = vm.load_model(active[\"id\"])\n",
        "        model = art[\"model\"]; pre = art[\"preprocessor\"]\n",
        "        X = pre.transform(df.drop(columns=[c for c in [\"default_flag\"] if c in df.columns], errors=\"ignore\"))\n",
        "        preds = model.predict_proba(X)[:,1]\n",
        "        out = df.copy()\n",
        "        out[\"default_risk\"] = preds\n",
        "        st.subheader(\"ðŸ”® Predictions\")\n",
        "        st.dataframe(out.head(50), use_container_width=True)\n",
        "        st.divider()\n",
        "        st.subheader(\"ðŸ“Š Insights\")\n",
        "        tab1, tab2, tab3 = st.tabs([\"Distribution\",\"Loan vs Risk\",\"Demographics\"])\n",
        "        with tab1:\n",
        "            st.bar_chart(out[\"default_risk\"])\n",
        "        with tab2:\n",
        "            if \"loan_amount\" in out.columns:\n",
        "                st.scatter_chart(out[[\"loan_amount\",\"default_risk\"]])\n",
        "        with tab3:\n",
        "            if \"age\" in out.columns:\n",
        "                st.metric(\"Average Age\", f\"{out['age'].mean():.1f} years\")\n",
        "            if \"household_income\" in out.columns:\n",
        "                st.metric(\"Average Income\", f\"KES {out['household_income'].mean():,.0f}\")\n",
        "\n",
        "        # Export\n",
        "        st.divider(); st.subheader(\"ðŸ“¤ Export\")\n",
        "        csv = out.to_csv(index=False).encode(\"utf-8\")\n",
        "        st.download_button(\"â¬‡ï¸ Download CSV\", data=csv, file_name=\"predictions.csv\", mime=\"text/csv\")\n",
        "\n",
        "        # PDF\n",
        "        import io\n",
        "        from reportlab.platypus import SimpleDocTemplate, Paragraph, Table, Spacer\n",
        "        from reportlab.lib.pagesizes import A4\n",
        "        from reportlab.lib.styles import getSampleStyleSheet\n",
        "        buf = io.BytesIO()\n",
        "        doc = SimpleDocTemplate(buf, pagesize=A4)\n",
        "        styles = getSampleStyleSheet()\n",
        "        elems = [Paragraph(\"LoanIQ Risk Report\", styles[\"Heading1\"]), Spacer(1,12)]\n",
        "        data = [list(out.columns)] + out.head(30).values.tolist()\n",
        "        elems.append(Table(data))\n",
        "        doc.build(elems)\n",
        "        st.download_button(\"â¬‡ï¸ Download PDF\", data=buf.getvalue(), file_name=\"predictions.pdf\", mime=\"application/pdf\")\n",
        "else:\n",
        "    st.info(\"Upload a CSV or click **Generate Sample Data**.\")\n",
        "\"\"\")\n",
        "\n",
        "# --- pages/admin_sandbox.py ---\n",
        "w(ROOT/\"pages/admin_sandbox.py\", \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from database.db_manager import DatabaseManager\n",
        "from models.model_versions import ModelVersionManager\n",
        "from models.ml_pipeline import MLPipeline\n",
        "from models.synthetic_data import SyntheticDataGenerator, GeneratorConfig\n",
        "\n",
        "def guard():\n",
        "    if \"user\" not in st.session_state or not st.session_state[\"user\"]:\n",
        "        st.switch_page(\"pages/login.py\")\n",
        "    if st.session_state.get(\"role\") != \"admin\":\n",
        "        st.switch_page(\"pages/client_dashboard.py\")\n",
        "guard()\n",
        "\n",
        "st.title(\"ðŸ› ï¸ LoanIQ Admin Sandbox\")\n",
        "st.info(f\"Welcome, {st.session_state['user']['email']} (Admin)\")\n",
        "\n",
        "db = DatabaseManager()\n",
        "vm = ModelVersionManager(db)\n",
        "\n",
        "tabs = st.tabs([\"Synthetic Generator\",\"Train/Deploy\",\"Versions\",\"DB Tools\"])\n",
        "\n",
        "# --- Synthetic Generator ---\n",
        "with tabs[0]:\n",
        "    st.markdown(\"### ðŸ§ª Controls\")\n",
        "    c1,c2,c3,c4 = st.columns(4)\n",
        "    with c1: n = st.number_input(\"Rows\", 500, 200_000, 5000, 500)\n",
        "    with c2: female = st.slider(\"Female share\", 0.30, 0.85, 0.62, 0.01)\n",
        "    with c3: dflt = st.slider(\"Default rate\", 0.03, 0.30, 0.12, 0.01)\n",
        "    with c4: seed = st.number_input(\"Seed\", 0, 9999, 42, 1)\n",
        "    if st.button(\"Generate Data\"):\n",
        "        cfg = GeneratorConfig(n_samples=int(n), female_share=float(female), default_rate_target=float(dflt), random_state=int(seed))\n",
        "        df = SyntheticDataGenerator(cfg).to_dataframe()\n",
        "        st.session_state[\"synthetic_df\"] = df\n",
        "        st.success(f\"Generated {len(df):,} rows. Default rate {df['default_flag'].mean():.2%}\")\n",
        "        st.dataframe(df.head(25), use_container_width=True)\n",
        "\n",
        "# --- Train/Deploy ---\n",
        "with tabs[1]:\n",
        "    st.markdown(\"### ðŸ¤– Train & Evaluate\")\n",
        "    fam = st.selectbox(\"Model family\", [\"LogReg\",\"RandomForest\",\"GradientBoosting\",\"XGBoost\",\"LightGBM\",\"Hybrid\"])\n",
        "    use_session = st.checkbox(\"Use generated dataset from tab 1 (if available)\", True)\n",
        "    if st.button(\"Train Model\"):\n",
        "        if use_session and \"synthetic_df\" in st.session_state:\n",
        "            df = st.session_state[\"synthetic_df\"]\n",
        "        else:\n",
        "            df = SyntheticDataGenerator().to_dataframe()\n",
        "        pipe = MLPipeline(fam)\n",
        "        auc, metrics, y_true, y_pred = pipe.train(df)\n",
        "        st.session_state[\"trained_model\"] = pipe\n",
        "        st.session_state[\"X_test\"] = None\n",
        "        st.session_state[\"y_test\"] = y_true\n",
        "        st.session_state[\"y_pred\"] = y_pred\n",
        "        st.success(f\"Trained {fam} â€” AUC: {auc:.3f}\")\n",
        "\n",
        "        # Performance charts\n",
        "        from sklearn.metrics import roc_curve, auc as _auc\n",
        "        import matplotlib.pyplot as plt\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "        roc_auc = _auc(fpr, tpr)\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.plot(fpr, tpr, label=f\"AUC={roc_auc:.2f}\")\n",
        "        ax.plot([0,1],[0,1],\"k--\")\n",
        "        ax.set_xlabel(\"FPR\"); ax.set_ylabel(\"TPR\"); ax.set_title(\"ROC Curve\"); ax.legend(loc=\"lower right\")\n",
        "        st.pyplot(fig)\n",
        "\n",
        "    if st.button(\"Deploy Active (save version)\"):\n",
        "        if \"trained_model\" not in st.session_state:\n",
        "            st.warning(\"Train a model first.\")\n",
        "        else:\n",
        "            pipe = st.session_state[\"trained_model\"]\n",
        "            vid = vm.save_model(fam, pipe.model, pipe.preprocessor_, {\"AUC\": float(np.round(np.mean(st.session_state[\"y_pred\"]>=0), 4))})\n",
        "            st.success(f\"Saved & activated version {vid}\")\n",
        "\n",
        "# --- Versions ---\n",
        "with tabs[2]:\n",
        "    st.markdown(\"### ðŸ“¦ Versions\")\n",
        "    versions = vm.list_versions()\n",
        "    if not versions:\n",
        "        st.info(\"No versions yet.\")\n",
        "    else:\n",
        "        st.dataframe(pd.DataFrame(versions), use_container_width=True)\n",
        "        choices = [v[\"id\"] for v in versions]\n",
        "        sel = st.selectbox(\"Activate version\", choices)\n",
        "        if st.button(\"Activate\"):\n",
        "            vm.set_active_version(sel)\n",
        "            st.success(f\"Activated {sel}\")\n",
        "\n",
        "# --- DB Tools ---\n",
        "with tabs[3]:\n",
        "    st.markdown(\"### ðŸ§± Schema & SQL\")\n",
        "    st.json(db.get_schema())\n",
        "    sql = st.text_area(\"Run SQL (dangerous!)\", height=120, placeholder=\"SELECT * FROM users;\")\n",
        "    if st.button(\"Execute SQL\"):\n",
        "        try:\n",
        "            db.execute_raw(sql)\n",
        "            st.success(\"Executed.\")\n",
        "        except Exception as e:\n",
        "            st.error(str(e))\n",
        "\"\"\")\n",
        "\n",
        "print(\"âœ… Cell 3 done â€” Streamlit pages written.\")"
      ],
      "metadata": {
        "id": "sBmthLvl4Y7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# LoanIQ â€” Cell 4/4\n",
        "# Helpers & finishing touches\n",
        "# =========================\n",
        "import pathlib, textwrap, pandas as pd\n",
        "ROOT = pathlib.Path(\".\")\n",
        "\n",
        "def w(path, content):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    path.write_text(textwrap.dedent(content).lstrip(), encoding=\"utf-8\")\n",
        "\n",
        "# .gitignore to keep repo clean\n",
        "w(ROOT/\".gitignore\", \"\"\"\n",
        "__pycache__/\n",
        "*.pyc\n",
        "loaniq.db\n",
        "artifacts/\n",
        "backups/\n",
        ".env\n",
        ".streamlit/\n",
        "\"\"\")\n",
        "\n",
        "# Optional: create a tiny sample CSV for quick testing\n",
        "from models.synthetic_data import SyntheticDataGenerator\n",
        "sample = SyntheticDataGenerator().to_dataframe().head(200)\n",
        "sample.to_csv(\"sample_loans.csv\", index=False)\n",
        "\n",
        "print(\"âœ… Cell 4 done â€” repo tidy, sample data saved.\")\n",
        "print(\"All files written. Commit to GitHub or push to Replit and run: streamlit run app.py\")"
      ],
      "metadata": {
        "id": "RiS9AiQ_4jWg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}